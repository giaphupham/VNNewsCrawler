Việt Nam nghiên cứu quy định về đạo đức AI 
Dựa trên kinh nghiệm ở nhiều nước và nguyên tắc của UNESCO, Việt Nam đang xây dựng quy định nhằm phát triển trí tuệ nhân tạo (AI) một cách có đạo đức, trách nhiệm.
Trong hội thảo "Phát triển và ứng dụng trí tuệ nhân tạo có trách nhiệm: Lý luận và thực tiễn", tổ chức sáng 28/2 tại Trường Đại học Luật, ĐHQGHN, Thứ trưởng Khoa học và Công nghệ Bùi Thế Duy, cho biết đạo đức AI là vấn đề phức tạp, quy mô toàn cầu, đang thu hút nhiều quốc gia, tổ chức trên thế giới tham gia tìm phương án giải quyết, gồm cả UNESCO.
"UNESCO là tổ chức thiên về văn hóa, giáo dục. Tuy nhiên, tổ chức này lần đầu tiên đưa trí tuệ nhân tạo - một nội dung thuộc lĩnh vực công nghệ, vào thảo luận. Động thái này thậm chí khiến một số nước từng rời bỏ tổ chức đã quyết định quay lại tham gia", ông nói.
Theo thứ trưởng, đạo đức AI ảnh hưởng tới đa dạng khía cạnh cuộc sống như xã hội, pháp lý, cạnh tranh chính trị và cạnh tranh thương mại. Để trí tuệ nhân tạo phát triển một cách có trách nhiệm, việc quản lý cần được xem trọng từ khâu xác định mô hình AI, thu thập dữ liệu, đến bước hoàn thiện hệ thống và đưa vào ứng dụng. Với thực tiễn Việt Nam, quá trình này cần sự phối hợp của kỹ sư, nhà khoa học và các cơ quan quản lý như Bộ Khoa học và Công nghệ, Bộ Thông tin và Truyền thông, Bộ Công an.
Cũng tại hội thảo, ông Duy cho biết nguyên tắc của UNESCO đang là cơ sở để các nước xây dựng quy định về đạo đức AI. Trước tiên, mô hình trí tuệ nhân tạo cần tuân thủ thiết kế, nhiệm vụ được thiết lập ngay từ đầu, nhằm đảm bảo không có các hành động phá hoại, gây tổn hại cho con người.
"AI khác hoàn toàn so với những công nghệ con người từng nghiên cứu. Trong khi các sản phẩm công nghệ cũ chỉ tuân thủ mục tiêu có sẵn, AI có thể tự tạo những hướng đi mới, vượt ra ngoài sự kiểm soát của nhà phát triển", ông nói. Thứ trưởng cũng lấy ví dụ về trường hợp các nhà khoa học cho hai hệ thống máy tính trò chuyện bằng tiếng Anh. Tuy nhiên, sau một khoảng thời gian, chúng bất ngờ chuyển sang giao tiếp bằng ngôn ngữ lạ, khiến nhóm nghiên cứu không thể nắm bắt nội dung hội thoại.
Vấn đề bình đẳng, công bằng cũng là nội dung cần được quan tâm khi xây dựng mô hình AI. Theo ông Duy, ngay từ bước thu thập thông tin để huấn luyện trí tuệ nhân tạo, việc bất bình đẳng đã có thể xảy ra và ảnh hưởng xấu tới toàn bộ hệ thống.
Với mô hình nhận diện giọng nói bằng AI, ông ví dụ nếu chỉ thu thập nguồn dữ liệu từ người Hà Nội, hệ thống sẽ sai lệch khi tương tác với người vùng miền khác. "Mở rộng ra, nguồn dữ liệu AI có thể gây bất công giữa các giới tính, các nhóm trong xã hội, ví dụ người khuyết tật", ông nói. Do đó, để có phát triển AI công bằng, ngoài sự tham gia của chuyên gia luật, còn cần đóng góp của chuyên gia tâm lý học, xã hội học.
Bên cạnh đó, đại diện Bộ cũng nhấn mạnh một số nguyên tắc quan trọng về đạo đức AI như đảm bảo an toàn dữ liệu cá nhân, tôn trọng quyền tác giả, bản quyền sở hữu trí tuệ, nâng cao năng suất lao động nhưng cần bảo vệ môi trường, an sinh xã hội.
Tại hội thảo, các chuyên gia cho biết Việt Nam đang theo dõi việc triển khai các quy định về phát triển AI có trách nhiệm tại nhiều quốc gia, khu vực trên thế giới, để có thể nghiên cứu và xây dựng khung pháp lý phù hợp với thực tiễn trong nước.
Cụ thể, cuối 2023, Liên minh Châu Âu đã thông qua các nguyên tắc trong đạo luật AI Act, dự kiến công bố muộn nhất vào quý II/2024. Đây hiện là bộ luật đầu tiên và toàn diện nhất, có nhiều sáng kiến nhằm đối phó với nguy cơ từ AI.
"AI Act 2024 sẽ dựa trên rủi ro của các mô hình AI để điều chỉnh luật pháp theo hướng tương ứng, cùng với đó là khung pháp lý thử nghiệm (sandbox) và cách tiếp cận 'mềm hóa' về đạo đức, độ tin cậy và tính trách nhiệm", TS Đỗ Giang Nam, Trường Đại học Luật, ĐHQGHN, nói tại hội thảo. Theo ông, kinh nghiệm từ bộ luật AI Act mà Việt Nam có thể ứng dụng là "không xây dựng luật một lần cho xong mà cần liên tục cập nhật, thích ứng với sự phát triển của công nghệ AI".
Khác với châu Âu, Mỹ lại xem xét các phản ứng từ khu vực tư nhân để xây dựng cách quản lý AI. Hiện Mỹ cũng là quốc gia có nhiều vụ kiện nhắm vào công ty AI nhất, đa phần liên quan đến vi phạm quyền riêng tư, phân biệt đối xử giữa các nhóm người lao động. Theo các chuyên gia, thay vì một bộ luật cố định, Mỹ có xu hướng ban hành nhiều nguyên tắc để các tổ chức, cá nhân có thể linh hoạt trong quá trình phát triển, ứng dụng mô hình AI.
Trung Quốc và Nhật Bản cũng là hai quốc gia có nhiều bước tiến trong việc phát triển AI có trách nhiệm. Từ 2019, quốc gia tỷ dân đã ban hành bốn nguyên tắc, tập trung vào người xây dựng mô hình, người sử dụng, quản trị AI và định hướng phát triển AI trong tương lai. Theo đó, Trung Quốc chọn cách vừa tự chủ phát triển AI, vừa đẩy mạnh quản trị trong nước, còn Nhật Bản hướng tới bộ quy tắc AI lấy con người làm trung tâm và vẫn đảm bảo tham gia được các diễn đàn quốc tế.
"Quá trình quản lý trí tuệ nhân tạo tại các nước cùng khu vực như Trung Quốc và Nhật Bản có thể là kinh nghiệm phát triển AI có trách nhiệm ở Việt Nam. Ngoài pháp lý, trách nhiệm ở đây còn là trách nhiệm với xã hội, con người", PGS.TS Nguyễn Thị Quế Anh, Hiệu trưởng Trường Đại học Luật, ĐHQGHN, cho biết. Ngoài ra, Việt Nam cũng đang xây dựng Luật Công nghiệp công nghệ số, trong đó có nội dung về đạo đức sản phẩm số, gồm cả trí tuệ nhân tạo.
Hội thảo nằm trong chuỗi các sự kiện của dự án "AI có trách nhiệm" trong khuôn khổ hoạt động trao đổi chính sách về đổi mới sáng tạo do chương trình Aus4Innovation tài trợ. Dự án nhằm hỗ trợ Bộ Khoa học và Công nghệ trong việc xây dựng khung hướng dẫn, dựa trên các kinh nghiệm từ Australia và quốc tế, giúp các tổ chức đang tham gia vào các hoạt động phát triển và sử dụng công nghệ AI có thể phát huy tối đa thế mạnh và giảm thiểu các tác động tiêu cực có thể của công nghệ này. 
Hoàng Giang
