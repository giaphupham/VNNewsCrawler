Hai nam sinh công bố nghiên cứu tại hội nghị AI hàng đầu thế giới 
Với phương pháp đào tạo đối nghịch để AI tạo thêm dữ liệu mới, nghiên cứu của hai sinh viên Bách khoa TP HCM được công bố ở AAAI - hội nghị về AI hàng đầu thế giới.
Nghiên cứu về mô hình đa ngôn ngữ huấn luyện AI (trí tuệ nhân tạo) tạo câu đồng nghĩa của Phạm Khánh Trình và Lê Minh Khôi, 23 tuổi, được đăng trong tài liệu Hội nghị AAAI-24, diễn ra cuối tháng 2 tại Vancouver, Canada.
PGS.TS Quản Thành Thơ, Phó trưởng khoa Khoa học và Kỹ thuật Máy tính, Đại học Bách khoa TP HCM, đánh giá đây là kết quả đáng khen ngợi. Thầy Thơ cho biết AAAI được giới nghiên cứu, chuyên gia đánh giá có chất lượng hàng đầu trong các hội nghị khoa học lĩnh vực khoa học máy tính, trí tuệ nhân tạo, với tỷ lệ chấp thuận bài báo rất thấp, năm nay là 23,75%.
Có chung niềm đam mê với Học sâu và Xử lý ngôn ngữ tự nhiên, Trình và Khôi chọn hướng nghiên cứu về mô hình ngôn ngữ lớn (LLMs). Cả hai muốn tìm ra những mặt hạn chế của LLMs và cải tiến nó.
Khánh Trình cho biết Chat GPT hay LLMs cần được huấn luyện một lượng dữ liệu văn bản khổng lồ để tạo ra các phản hồi chính xác, đa dạng cho người dùng. Hai nam sinh nhận ra với các ngôn ngữ ít phổ biến như tiếng Hindi, Kazakh, hay Indonesia, Chat GPT và LLMs thường cho ra kết quả không như mong đợi vì chưa được học nhiều thứ tiếng này, hoặc thứ tiếng này chưa đủ dữ liệu cho chúng học.
"Tại sao chúng ta không tạo thêm dữ liệu dạng chữ từ những 'tài nguyên ít ỏi' của các thứ tiếng đó để huấn luyện thêm cho AI", hai nam sinh đặt vấn đề. Từ đó mô hình LAMPAT (Low-rank Adaptation for Multilingual Paraphrasing using Adversarial Training) - diễn giải đa ngôn ngữ bằng cách sử dụng phương pháp đào tạo đối nghịch do Trình và Khôi nghiên cứu, ra đời.
LAMPAT có khả năng tạo một câu đồng nghĩa từ một câu đầu vào có sẵn, nhằm sinh thêm dữ liệu dạng chữ. Trình giải thích "đào tạo đối nghịch" là một phương pháp tương đối mới trong huấn luyện các mô hình ngôn ngữ lớn. Khi đưa một câu đầu vào, với phương pháp huấn luyện truyền thống, ứng dụng sẽ tạo một câu đầu ra. Nhưng với phương pháp đào tạo đối nghịch, ứng dụng có thể tự nhận xét, chỉnh sửa câu đầu ra, "đối nghịch với chính nó" để tạo thêm nhiều câu khác.
Lượng dữ liệu dạng chữ được tạo ra từ LAMPAT sẽ tiếp tục được mang đi huấn luyện cho LLMs để các mô hình này học được nhiều kiểu diễn đạt thông tin khác nhau cho cùng một nội dung, từ đó cho kết quả phản hồi đa dạng và có xác suất đúng cao hơn. Với tính năng này, đại diện nhóm cho rằng LAMPAT có thể được tích hợp vào các ứng dụng như ChatGPT để hoàn thiện hơn mô hình này.
Bên cạnh đó, tình trạng thiếu dữ liệu cho Chat GPT hay LLMs khiến một số công ty phải tìm kiếm nhiều nguồn từ bên ngoài như sách, báo, blog,... mà không để ý đến vấn đề bản quyền. Việc tạo câu đồng nghĩa cũng là một trong những cách để hạn chế tình trạng đạo văn, vi phạm bản quyền, theo Khánh Trình.
Nam sinh ví dụ với các ứng dụng như Chat GPT, khi người dùng yêu cầu tóm tắt một văn bản có sẵn A, ứng dụng sẽ tạo ra một văn bản tóm tắt B. Nếu tích hợp phương pháp nghiên cứu của nhóm, khi tiếp nhận văn bản A, ứng dụng sẽ tạo ra nhiều văn bản cùng nội dung A1, A2, A3 dựa trên cơ chế tạo câu đồng nghĩa, từ đó mới tóm tắt văn bản và cho ra nhiều kết quả để người dùng lựa chọn.
Trong thời gian đầu nghiên cứu, nhóm gặp khó khăn khi chuẩn bị dữ liệu đánh giá cho 60 thứ tiếng. Do chưa thể tiếp cận với số lượng dữ liệu đủ lớn nên nhóm đã tổng hợp bộ dữ liệu đa dạng, đầy đủ của 13 thứ tiếng để đánh giá khách quan mô hình, gồm: Việt, Anh, Pháp, Đức, Nga, Nhật, Trung, Tây Ban Nha, Hungary, Bồ Đào Nha, Thụy Điển, Phần Lan, Séc. Đây cũng là bộ dữ liệu đáng tin cậy cho bước Human Evaluation (chấm điểm) cuối cùng.
Đối với mỗi ngôn ngữ tiếng Anh, Việt, Đức, Pháp và Nhật, nhóm trích xuất ngẫu nhiên 200 cặp câu (một cặp gồm câu đầu ra và nhãn đúng) để đánh giá. Với mỗi ngôn ngữ nêu trên, nhóm nhờ 5 chuyên gia ngôn ngữ chấm điểm độc lập, dựa trên ba tiêu chí: bảo toàn ngữ nghĩa; cách lựa chọn từ ngữ và độ tương đồng về từ vựng, tính trôi chảy và mạch lạc của câu đầu ra. Thang đo được tính từ 1 đến 5. Kết quả, điểm đánh giá trung bình từ chuyên gia ngôn ngữ ở 5 thứ tiếng này dao động 4,2-4,6/5 điểm.
Một cặp câu tiếng Việt được chấm điểm 4,4/5, trong đó câu đầu vào là: "Anh ta đã giải thích vấn đề ấy một cách chi tiết", và câu đầu ra: "Anh ta đã giải thích chi tiết vấn đề ấy".
Nhưng cũng có những cặp câu không tốt, sai ngữ nghĩa, như cặp câu "Chúng tôi ăn trong khi súp nóng - Chúng tôi ăn súp trong khi chúng tôi đang nóng", chỉ đạt 2/5 điểm.
Khánh Trình cho hay mất 8 tháng để hoàn thành nghiên cứu này. Đây cũng là đề tài luận văn tốt nghiệp của Trình và Khôi, đứng đầu khi bảo vệ ở Hội đồng Khoa học Máy tính 2 với 9,72/10 điểm.
Theo thầy Quản Thành Thơ, dù LAMPAT chứng tỏ khả năng thành thạo trong việc tạo ra các cụm diễn giải đồng nghĩa giống con người trên nhiều ngôn ngữ, nhưng nó vẫn cần cải tiến để xử lý các thành ngữ, ca dao, tục ngữ ở các thứ tiếng khác nhau.
Hơn nữa, tập dữ liệu đánh giá của nhóm chỉ gồm 13 ngôn ngữ, vẫn còn bỏ sót nhiều, nhất là tiếng dân tộc thiểu số. Vì vậy, nhóm cần nghiên cứu để nâng cao và mở rộng khả năng của các mô hình diễn giải đa ngôn ngữ hiện nay. Từ đây, chúng ta có thể gỡ bỏ được rào cản ngôn ngữ giữa các quốc gia và dân tộc.
Cuối năm 2023, Trình và Khôi tốt nghiệp cử nhân Khoa học Máy tính loại giỏi và xuất sắc với điểm trung bình (GPA) lần lượt là 3.7 và 3.9/4. Cả hai định du học thạc sĩ và đi theo con đường nghiên cứu về trí tuệ nhân tạo, học máy.
"Chúng mình vẫn tiếp tục nghiên cứu đề tài này với mục tiêu ứng dụng LAMPAT nhiều hơn vào các công trình khoa học sắp tới, tạo được một sản phẩm đa ngôn ngữ đáng tin cậy cho người dùng", Trình chia sẻ.
Lệ Nguyễn 
